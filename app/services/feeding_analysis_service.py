# ============================================================
# æ–‡ä»¶è¯´æ˜: feeding_analysis_service.py - æŠ•æ–™è‡ªåŠ¨åˆ†ææœåŠ¡
# ============================================================
# åŠŸèƒ½:
# 1. è‡ªåŠ¨åˆ†æ: æ¯6å°æ—¶è¿è¡Œä¸€æ¬¡
# 2. æ•°æ®æº: æŸ¥è¯¢InlfuxDBè¿‡å»6å°æ—¶çš„æ–™ä»“é‡é‡æ•°æ® (10åˆ†é’Ÿèšåˆ)
# 3. ç®—æ³•: è¯†åˆ«æŠ•æ–™äº‹ä»¶ (é‡é‡æ¿€å¢) å¹¶è®¡ç®—æŠ•æ–™é‡
# 4. å­˜å‚¨: å°†è®¡ç®—ç»“æœå­˜å› InfluxDB (measurement="feeding_records")
# ============================================================

import asyncio
import math
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional

from config import get_settings
from app.core.influxdb import get_influx_client, write_points_batch
from app.services.history_query_service import HistoryQueryService
from app.services.polling_service import get_latest_data
# å¼•å…¥ InfluxDB å†™å…¥ Point ç»“æ„
from influxdb_client import Point
from influxdb_client.client.write_api import SYNCHRONOUS

settings = get_settings()

class FeedingAnalysisService:
    def __init__(self):
        self._is_running = False
        self._task = None
        self.run_interval_minutes = 120   # è¿è¡Œé¢‘ç‡: 2å°æ—¶æ£€æµ‹ä¸€æ¬¡
        self.query_window_hours = 24      # æŸ¥è¯¢çª—å£: å›æº¯è¿‡å»24å°æ—¶ (1å¤©)
        self.aggregation_window = "30m"   # èšåˆç²’åº¦: æ”¾å®½åˆ°30åˆ†é’Ÿ
        self.history_service = HistoryQueryService()

    def start(self):
        """å¯åŠ¨åå°åˆ†æä»»åŠ¡"""
        if self._is_running:
            return
        self._is_running = True
        self._task = asyncio.create_task(self._scheduled_loop())
        print(f"ğŸš€ [FeedingService] æŠ•æ–™åˆ†ææœåŠ¡å·²å¯åŠ¨ (Frequency: {self.run_interval_minutes}m, Window: {self.query_window_hours}h)")

    def stop(self):
        """åœæ­¢æœåŠ¡"""
        self._is_running = False
        if self._task:
            self._task.cancel()

    async def _scheduled_loop(self):
        """è°ƒåº¦å¾ªç¯"""
        # åˆæ¬¡å¯åŠ¨ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œé¿å…å’Œç³»ç»Ÿåˆå§‹åŒ–å†²çª
        await asyncio.sleep(60)
        
        while self._is_running:
            try:
                print(f"ğŸ“Š [FeedingService] å¼€å§‹æ‰§è¡ŒæŠ•æ–™åˆ†æä»»åŠ¡...")
                await self._analyze_feeding_job()
                print(f"âœ… [FeedingService] åˆ†æä»»åŠ¡å®Œæˆï¼Œä¸‹æ¬¡è¿è¡Œåœ¨ {self.run_interval_minutes} åˆ†é’Ÿå")
            except Exception as e:
                print(f"âŒ [FeedingService] åˆ†æä»»åŠ¡å¼‚å¸¸: {e}")
            
            # ç­‰å¾…è®¾å®šçš„é—´éš”
            await asyncio.sleep(self.run_interval_minutes * 60)

    async def _analyze_feeding_job(self):
        """æ‰§è¡Œå…·ä½“çš„åˆ†æé€»è¾‘"""
        now = datetime.now(timezone.utc)
        # å…³é”®ä¿®æ”¹: æ— è®ºè¿è¡Œé¢‘ç‡å¦‚ä½•ï¼Œå§‹ç»ˆå›æº¯æŸ¥è¯¢ query_window_hours çš„æ•°æ®
        # è¿™æ ·å¯ä»¥ç¡®ä¿æ•è·è·¨è¶Šè¾¹ç•Œçš„äº‹ä»¶ï¼Œå¹¶é€šè¿‡ InfluxDB çš„å¹‚ç­‰å†™å…¥ç‰¹æ€§æ›´æ–°/ä¿®æ­£è®°å½•
        start_time = now - timedelta(hours=self.query_window_hours)
        
        # 1. è·å–æ‰€æœ‰æ–™ä»“è®¾å¤‡ (è¿‡æ»¤ no_hopper)
        hopper_devices = self._get_hopper_devices()
        print(f"   ğŸ“‹ ç›®æ ‡è®¾å¤‡: {len(hopper_devices)} å° ({', '.join(hopper_devices)})")
        
        results = []
        
        for device_id in hopper_devices:
            # å»¶è¿Ÿ5ç§’ï¼Œé˜²æ­¢é«˜å¹¶å‘æŸ¥è¯¢å¯¼è‡´ç³»ç»Ÿå´©æºƒ
            await asyncio.sleep(5)
            
            # 2. æŸ¥è¯¢å†å²æ•°æ® (èšåˆ)
            records = self._query_history_weights(device_id, start_time, now)
            if not records:
                continue
                
            # 3. è®¡ç®—æŠ•æ–™é‡
            feeding_events = self._detect_and_calculate_feeding(records, device_id)
            if feeding_events:
                results.extend(feeding_events)
                print(f"      ğŸ”¹ è®¾å¤‡ {device_id}: å‘ç° {len(feeding_events)} æ¬¡æŠ•æ–™")

        # 4. æ‰¹é‡ä¿å­˜ç»“æœ
        if results:
            self._save_feeding_records(results)

    def _get_hopper_devices(self) -> List[str]:
        """è·å–æ‰€æœ‰å¸¦æ–™ä»“çš„è®¾å¤‡ID"""
        # ä» polling_service çš„ latest_data è·å–è®¾å¤‡åˆ—è¡¨æœ€å‡†ç¡®
        # è¿™é‡Œç®€åŒ–é€»è¾‘: æˆ‘ä»¬çŸ¥é“æ˜¯ short_hopper_XX å’Œ long_hopper_XX
        # ä¹Ÿå¯ä»¥ä»é…ç½®è¯»å–ï¼Œæˆ–è€…ç¡¬ç¼–ç å·²çŸ¥IDè§„åˆ™
        # åŠ¨æ€è·å–æ›´å¥½ï¼š
        devices = []
        latest = get_latest_data()
        for device_id, data in latest.items():
            if "no_hopper" in device_id:
                continue
            # å¿…é¡»åŒ…å« weigh æ¨¡å—
            has_weigh = False
            if 'modules' in data:
                for m_data in data['modules'].values():
                    if m_data.get('module_type') == 'WeighSensor':
                        has_weigh = True
                        break
            
            if has_weigh:
                devices.append(device_id)
        
        # å¦‚æœè¿˜åœ¨å¯åŠ¨ä¸­æ²¡æ•°æ®ï¼Œä½¿ç”¨é¢„è®¾åˆ—è¡¨
        if not devices:
            return [
                'short_hopper_1', 'short_hopper_2', 'short_hopper_3', 'short_hopper_4',
                'long_hopper_1', 'long_hopper_2', 'long_hopper_3'
            ]
        return devices

    def _query_history_weights(self, device_id: str, start: datetime, end: datetime) -> List[Dict]:
        """æŸ¥è¯¢èšåˆåçš„é‡é‡å†å²"""
        query = f'''
        from(bucket: "{settings.influx_bucket}")
            |> range(start: {start.isoformat().replace("+00:00", "Z")}, stop: {end.isoformat().replace("+00:00", "Z")})
            |> filter(fn: (r) => r["_measurement"] == "sensor_data")
            |> filter(fn: (r) => r["device_id"] == "{device_id}")
            |> filter(fn: (r) => r["_field"] == "weight")
            |> aggregateWindow(every: {self.aggregation_window}, fn: mean, createEmpty: false)
            |> yield(name: "mean")
        '''
        
        try:
            result = self.history_service.query_api.query(query)
            data_points = []
            for table in result:
                for record in table.records:
                    val = record.get_value()
                    if val is not None:
                        data_points.append({
                            "time": record.get_time(),
                            "value": float(val)
                        })
            # æŒ‰æ—¶é—´æ’åº
            data_points.sort(key=lambda x: x['time'])
            return data_points
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢ {device_id} å¤±è´¥: {e}")
            return []

    def _detect_and_calculate_feeding(self, records: List[Dict], device_id: str) -> List[Point]:
        """
        æ ¸å¿ƒç®—æ³•: è¯†åˆ«æŠ•æ–™å¹¶è®¡ç®— (Enhanced Logic v2 - å¸¦å»é‡)
        
        é€»è¾‘æµç¨‹:
        1. å¯»æ‰¾ Valley (æŠ•æ–™å¼€å§‹å‰çš„æœ€ä½ç‚¹)
        2. è¿½è¸ª Rising Edge (è¿ç»­ä¸Šå‡åŒºé—´), è®¡æ•°é—´éš” x
        3. ç¡®å®š Peak (æŠ•æ–™ç»“æŸåçš„æœ€é«˜ç‚¹)
        4. è®¡ç®—æ¶ˆè€—è¡¥å¿ Consumption
           - å¯»æ‰¾ Pre-Valley Slope (æŠ•æ–™å‰çš„æ¶ˆè€—é€Ÿç‡)
           - Consumption = (Consumption_Rate_Per_Interval) * x
        5. Total Added = (Peak - Valley) + Consumption
        6. é˜ˆå€¼: Rising amount > 10kg
        7. [NEW] å»é‡: æ¯æ¬¡æ£€æµ‹åè®¾ç½®å†·å´æœŸï¼Œé˜²æ­¢åŒä¸€ä¸Šå‡åŒºé—´è¢«é‡å¤è®°å½•
        """
        events = []
        n = len(records)
        if n < 2:
            return []

        # é˜ˆå€¼: åªæœ‰ä¸Šå‡æ€»é«˜åº¦è¶…è¿‡æ­¤å€¼æ‰è§¦å‘å¤æ‚è®¡ç®—
        # ç”¨æˆ·éœ€æ±‚: > 10kg å³ä¸ºæœ‰æ•ˆæŠ•æ–™
        THRESHOLD = 10.0 
        
        # [NEW] å†·å´æœŸ: è®°å½•ä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„ Peak ç´¢å¼•ï¼Œé¿å…é‡å¤æ£€æµ‹
        last_peak_idx = -1
        
        i = 1
        while i < n:
            # [NEW] è·³è¿‡å†·å´æœŸå†…çš„ç‚¹
            if i <= last_peak_idx:
                i += 1
                continue
                
            curr = records[i]
            prev = records[i-1]
            
            # æ£€æµ‹åˆ°èµ·æ­¥ä¸Šå‡
            if curr['value'] > prev['value'] + 5.0: # è‡³å°‘æœ‰å¾®å°ä¸Šå‡æ‰å¼€å§‹è¿½è¸ª
                valley_idx = i - 1
                valley_val = prev['value']
                
                # è¿½è¸ªè¿ç»­ä¸Šå‡ (å…è®¸å¶å°”æŒå¹³æˆ–æå°å›è½/æŠ–åŠ¨è§†ä¸ºä¸Šå‡è¿‡ç¨‹)
                # å¯»æ‰¾ Peak
                peak_idx = i
                while peak_idx < n - 1:
                    next_val = records[peak_idx+1]['value']
                    curr_val = records[peak_idx]['value']
                    
                    # å¦‚æœä»åœ¨ä¸Šå‡
                    if next_val >= curr_val:
                        peak_idx += 1
                        continue
                        
                    # å¦‚æœä¸‹é™äº†ï¼Œä½†å¯èƒ½åªæ˜¯æ³¢åŠ¨ï¼ˆæ¯”å¦‚ä¸‹é™å¾ˆå°‘ï¼‰ï¼Œå¯ä»¥å‘åå¤šçœ‹å‡ ä¸ªç‚¹ï¼Ÿ
                    # [FIX] å¢åŠ  Lookahead æœºåˆ¶ï¼Œé˜²æ­¢å› ä¸´æ—¶å¾®å°æ³¢åŠ¨å¯¼è‡´æŠ•æ–™è¯¯åˆ¤æå‰ç»“æŸ
                    if next_val < curr_val:
                        # æ£€æŸ¥æœªæ¥ 3 ä¸ªç‚¹ï¼Œçœ‹æ˜¯å¦æœ‰åå¼¹ï¼ˆè¶…è¿‡å½“å‰å€¼ï¼‰
                        is_fluctuation = False
                        lookahead_steps = 3
                        for k in range(1, lookahead_steps + 1):
                            if peak_idx + 1 + k >= n: 
                                break # æ•°æ®ä¸å¤Ÿäº†
                            future_val = records[peak_idx + 1 + k]['value']
                            if future_val >= curr_val:
                                # å‘ç°åé¢åˆæ¶¨ä¸Šå»äº†ï¼Œè¯´æ˜åˆšæ‰åªæ˜¯æ³¢åŠ¨
                                is_fluctuation = True
                                # è·³è¿‡ä¸­é—´çš„æ³¢åŠ¨ç‚¹ï¼Œç›´æ¥æŠŠ peak_idx ç§»åˆ°è¿™ä¸ªæ›´é«˜çš„ç‚¹å‰ä¸€ä¸ªï¼ˆå› ä¸ºå¾ªç¯æœ«å°¾ä¼š+1ï¼‰
                                peak_idx += k 
                                break
                        
                        if is_fluctuation:
                            peak_idx += 1
                            continue # ç»§ç»­è¿½è¸ªä¸Šå‡
                            
                        # ç¡®å®ä¸‹é™äº†ï¼Œä¸”çŸ­æœŸæ²¡åå¼¹
                        # åªæœ‰ä¸‹é™å¹…åº¦è¶…è¿‡é˜ˆå€¼ï¼ˆä¾‹å¦‚ 5.0kgï¼‰æ‰è®¤ä¸ºæ˜¯çœŸæ­£çš„ç»“æŸï¼Œæˆ–è€…æ˜¯æŒç»­ä¸‹é™
                        drop_diff = curr_val - next_val
                        if drop_diff > 5.0: 
                             break # æ˜¾è‘—ä¸‹é™ï¼Œè®¤å®šæŠ•æ–™åœæ­¢
                        
                        # å¦‚æœæ˜¯å¾®å°ä¸‹é™ä¸”æ²¡åå¼¹ï¼ˆå¯èƒ½æ˜¯å¹³ç¼“æœŸï¼‰ï¼Œç»§ç»­å¾€åçœ‹ï¼Ÿ
                        # è¿™ç§æƒ…å†µä¸‹é€šå¸¸ä¹Ÿè®¤ä¸ºæ˜¯é¡¶å³°äº†ï¼Œé™¤éä¸‹é™çœŸçš„å¾ˆå° (<5.0kg)
                        # å¦‚æœä¸‹é™å¾ˆå°ï¼Œè®©ä»–ç»§ç»­èµ°ï¼Œå¯èƒ½ä¼šé‡åˆ°æ›´å¤§çš„ä¸‹é™æˆ–ä¸Šå‡
                        # ä½†ä¸ºäº†å®‰å…¨ï¼Œå¦‚æœ continuous decrease...
                        
                    peak_idx += 1
                
                # [CRITICAL FIX] è¾¹ç¼˜æ£€æµ‹ä¿æŠ¤
                # å¦‚æœå¾ªç¯æ˜¯å› ä¸ºåˆ°äº†æ•°æ®æœ«å°¾ (peak_idx == n-1) è€Œç»“æŸï¼Œè¯´æ˜æŠ•æ–™è¿‡ç¨‹å¯èƒ½ä»åœ¨ç»§ç»­ï¼ˆæˆ–è€…åˆšè¾¾åˆ°å³°å€¼ä½†è¿˜æ²¡å¼€å§‹ä¸‹é™ï¼‰
                # æ­¤æ—¶ä¸èƒ½ä»“ä¿ƒä¸‹ç»“è®ºï¼Œåº”è¯¥è·³è¿‡æœ¬æ¬¡è®¡ç®—ï¼Œç­‰å¾…æ›´å¤šæ•°æ®è¿›æ¥åå†ç¡®è®¤
                if peak_idx >= n - 1:
                    # è®°å½•è°ƒè¯•ä¿¡æ¯ä½†ä¸ä¿å­˜
                    # print(f"      â³ æŠ•æ–™æœªç»“æŸ (Edge case): {records[valley_idx]['time']} -> {records[peak_idx]['time']}, ç­‰å¾…æ›´å¤šæ•°æ®...")
                    break
                
                peak_val = records[peak_idx]['value']
                raw_increase = peak_val - valley_val
                
                # åˆ¤æ–­æ˜¯å¦æ»¡è¶³ > 50kg çš„è§¦å‘æ¡ä»¶
                if raw_increase > THRESHOLD:
                    # è®¡ç®—æŒç»­é—´éš”æ•° x
                    # 10åˆ†é’Ÿä¸€ä¸ªç‚¹ã€‚é—´éš”æ•°å³ peak_idx - valley_idx
                    x_intervals = peak_idx - valley_idx
                    
                    # è®¡ç®— Pre-Valley çš„æ¶ˆè€—é€Ÿç‡
                    # å¯»æ‰¾ valley å‰é¢å‡ ä¸ªç‚¹æ¥ä¼°ç®—æ–œç‡
                    consumption_rate = 0.0
                    if valley_idx >= 1:
                        # åªçœ‹å‰ä¸€ä¸ªåŒºé—´ (PreValley - Valley)
                        # ç”¨æˆ·: "(PreValley - Valley)"
                        pre_valley_val = records[valley_idx-1]['value']
                        rate = pre_valley_val - valley_val
                        if rate > 0:
                            consumption_rate = rate
                        
                        # ä¹Ÿå¯ä»¥å¤šçœ‹å‡ ä¸ªå–å¹³å‡ï¼Œä½†ç”¨æˆ·ä¼¼ä¹å€¾å‘äºåªçœ‹å‰ä¸€ä¸ª
                    
                    # å¦‚æœå‰ä¸€ä¸ªæ²¡æœ‰æ•°æ®ï¼ˆæ¯”å¦‚åˆšå¼€å§‹æŸ¥ï¼‰ï¼Œè®¾å®šä¸€ä¸ªé»˜è®¤æœ€å°æ¶ˆè€—é€Ÿç‡ï¼Ÿ
                    # æš‚æ—¶ä¿æŒ 0
                    
                    # æ ¸å¿ƒå…¬å¼: Peak - Valley + (Consumption_Rate * x)
                    # ç”¨æˆ·åŸè¯: "ä¹˜ä»¥xäº†"
                    compensation = consumption_rate * x_intervals
                    
                    total_added = raw_increase + compensation
                    
                    # æ„å»ºè®°å½• 
                    # [Changed] ä½¿ç”¨ Valley (å¼€å§‹ä¸Šå‡ç‚¹) ä½œä¸ºè®°å½•æ—¶é—´æˆ³ï¼Œè€Œé Peak
                    # è¿™æ ·å¯ä»¥ä¿è¯æ¯æ¬¡è®¡ç®—çš„æ—¶é—´æˆ³ä¸€è‡´æ€§ï¼ˆåŸºäºåŸå§‹æ•°æ®ç‚¹ï¼‰ï¼Œå®ç° InfluxDB å¤©ç„¶å»é‡
                    p = Point("feeding_records") \
                        .tag("device_id", device_id) \
                        .field("added_weight", float(total_added)) \
                        .field("raw_increase", float(raw_increase)) \
                        .field("duration_intervals", int(x_intervals)) \
                        .field("compensation", float(compensation)) \
                        .time(records[valley_idx]['time'])
                    
                    events.append(p)
                    
                    # [CRITICAL] è®¾ç½®å†·å´æœŸ: è·³è¿‡å·²å¤„ç†çš„æ•´ä¸ªä¸Šå‡åŒºé—´
                    # ä¸‹ä¸€æ¬¡æ£€æµ‹å¿…é¡»ä» peak_idx + 1 å¼€å§‹
                    last_peak_idx = peak_idx
                    i = peak_idx + 1
                    
                    print(f"      âœ… æ£€æµ‹åˆ°æŠ•æ–™: Valley={records[valley_idx]['time']}, Peak={records[peak_idx]['time']}, Added={total_added:.1f}kg")
                else:
                    # æ²¡è¶…è¿‡é˜ˆå€¼ï¼Œå¯èƒ½æ˜¯å°æ³¢åŠ¨ï¼Œç»§ç»­
                    i += 1
            else:
                i += 1
                
        return events

    def _save_feeding_records(self, points: List[Point]):
        """ä¿å­˜åˆ° InfluxDB"""
        try:
            write_api = self.history_service.client.write_api(write_options=SYNCHRONOUS)
            write_api.write(bucket=settings.influx_bucket, record=points)
            print(f"ğŸ’¾ å·²ä¿å­˜ {len(points)} æ¡æŠ•æ–™è®°å½•")
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ•æ–™è®°å½•å¤±è´¥: {e}")

# å•ä¾‹å¯¼å‡º
feeding_service = FeedingAnalysisService()
